Time to build graph: 305.7929663658142 seconds
##############################################################################
printing model variables:
seq2seq/embedding/embedding:0: shape=[50, 10], variable_parameters=500
seq2seq/encoder/word_level_encoder/bidirectional_rnn/fw/lstm_cell/kernel:0: shape=[34, 96], variable_parameters=3264
seq2seq/encoder/word_level_encoder/bidirectional_rnn/fw/lstm_cell/bias:0: shape=[96], variable_parameters=96
seq2seq/encoder/word_level_encoder/bidirectional_rnn/bw/lstm_cell/kernel:0: shape=[34, 96], variable_parameters=3264
seq2seq/encoder/word_level_encoder/bidirectional_rnn/bw/lstm_cell/bias:0: shape=[96], variable_parameters=96
seq2seq/encoder/word_level_encoder/reduce_final_st/w_reduce_c:0: shape=[48, 24], variable_parameters=1152
seq2seq/encoder/word_level_encoder/reduce_final_st/w_reduce_h:0: shape=[48, 24], variable_parameters=1152
seq2seq/encoder/word_level_encoder/reduce_final_st/bias_reduce_c:0: shape=[24], variable_parameters=24
seq2seq/encoder/word_level_encoder/reduce_final_st/bias_reduce_h:0: shape=[24], variable_parameters=24
seq2seq/encoder/section_level_encoder/bidirectional_rnn/fw/lstm_cell/kernel:0: shape=[48, 96], variable_parameters=4608
seq2seq/encoder/section_level_encoder/bidirectional_rnn/fw/lstm_cell/bias:0: shape=[96], variable_parameters=96
seq2seq/encoder/section_level_encoder/bidirectional_rnn/bw/lstm_cell/kernel:0: shape=[48, 96], variable_parameters=4608
seq2seq/encoder/section_level_encoder/bidirectional_rnn/bw/lstm_cell/bias:0: shape=[96], variable_parameters=96
seq2seq/encoder/section_level_encoder/reduce_final_st/w_reduce_c:0: shape=[48, 24], variable_parameters=1152
seq2seq/encoder/section_level_encoder/reduce_final_st/w_reduce_h:0: shape=[48, 24], variable_parameters=1152
seq2seq/encoder/section_level_encoder/reduce_final_st/bias_reduce_c:0: shape=[24], variable_parameters=24
seq2seq/encoder/section_level_encoder/reduce_final_st/bias_reduce_h:0: shape=[24], variable_parameters=24
seq2seq/decoder/attention_decoder/W_h:0: shape=[1, 1, 48, 48], variable_parameters=2304
seq2seq/decoder/attention_decoder/W_h_s:0: shape=[1, 1, 48, 48], variable_parameters=2304
seq2seq/decoder/attention_decoder/v_sec:0: shape=[48], variable_parameters=48
seq2seq/decoder/attention_decoder/v:0: shape=[48], variable_parameters=48
seq2seq/decoder/attention_decoder/Linear/Matrix:0: shape=[58, 10], variable_parameters=580
seq2seq/decoder/attention_decoder/Linear/Bias:0: shape=[10], variable_parameters=10
seq2seq/decoder/attention_decoder/lstm_cell/kernel:0: shape=[34, 96], variable_parameters=3264
seq2seq/decoder/attention_decoder/lstm_cell/bias:0: shape=[96], variable_parameters=96
seq2seq/decoder/attention_decoder/Attention/Linear/Matrix:0: shape=[48, 48], variable_parameters=2304
seq2seq/decoder/attention_decoder/Attention/Linear/Bias:0: shape=[48], variable_parameters=48
seq2seq/decoder/attention_decoder/Attention/attention_sections/Linear--Section-Features/Matrix:0: shape=[48, 48], variable_parameters=2304
seq2seq/decoder/attention_decoder/Attention/attention_sections/Linear--Section-Features/Bias:0: shape=[48], variable_parameters=48
seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Matrix:0: shape=[106, 1], variable_parameters=106
seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Bias:0: shape=[1], variable_parameters=1
seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Matrix:0: shape=[72, 24], variable_parameters=1728
seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Bias:0: shape=[24], variable_parameters=24
seq2seq/output_projection/w:0: shape=[24, 50], variable_parameters=1200
seq2seq/output_projection/b:0: shape=[50], variable_parameters=50
total model parameters: 37799
##############################################################################